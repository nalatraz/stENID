{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply model to sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ENID.acquisition import *\n",
    "from ENID.interpolation import *\n",
    "from alerce.core import Alerce\n",
    "from time import gmtime, strftime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import george"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasources = pd.read_csv('sourceone.csv',header=None) # Give your sources in a .csv file with the ZTF-names. An example with blue continuum sources is attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wanted\n",
    "ModelWeights = 'Models/Simple GRU/Weights'\n",
    "\n",
    "# Name of the saved files\n",
    "Version = strftime(\"%Y%m%d%H%M%S\",gmtime()) #Default used UTC time and date.\n",
    "\n",
    "# Number of points before\n",
    "timediff = 14\n",
    "noofpoint = 2\n",
    "\n",
    "# Plotting?\n",
    "plotbool = 'n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_ENID(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers):\n",
    "        super(simple_ENID, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.GRU = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, bidirectional=False) \n",
    "        self.Dense = nn.Linear(hidden_dim, output_dim)\n",
    "        self.predict = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_, h_ = self.GRU(x)\n",
    "        x_ = self.Dense(x_[:,-1])\n",
    "        x_ = self.predict(x_)\n",
    "        \n",
    "        return x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sources : 1 \n",
      "\n",
      "Found  1 objects\n",
      "Missing  0 objects\n",
      "\n",
      "Importing lightcurve and metadata for  \u001b[1mZTF19abzwbxy\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "##### Retrieve light curves part\n",
    "\n",
    "# Get ready by making it a list anc checking that they are not floats\n",
    "ztf_raw = list(datasources[0])\n",
    "ztf_names = [x for x in ztf_raw if type(x) != float]\n",
    "\n",
    "# Find the sources on ALeRCE\n",
    "print('Number of sources :', len(ztf_raw), '\\n')\n",
    "alerce_found, alerce_missing = source_search_alerce(ztf_names)\n",
    "\n",
    "# Tell how many were found\n",
    "print('Found ', alerce_found.shape[0], 'objects')\n",
    "print('Missing ', len(alerce_missing), 'objects')\n",
    "\n",
    "if len(alerce_missing) > 0:\n",
    "    for mis in alerce_missing:\n",
    "        print('Missing ', alerce_missing['oid'][mis])\n",
    "\n",
    "# Get the object id for each source\n",
    "sources = list(alerce_found['oid'])\n",
    "\n",
    "# Retrieve the lightcurves for the sources\n",
    "object_dictionary = {\"Name\": [], \"Data\": [], \"Label\": []}\n",
    "\n",
    "for i in range(len(sources)):\n",
    "    \n",
    "    \n",
    "    lightcurve = lc_compile(sources[i])\n",
    "    if len(lightcurve['R_mag']) > 1 and len(lightcurve['G_mag']) > 1:\n",
    "        object_dictionary['Data'].append(lightcurve)\n",
    "        object_dictionary['Name'].append(ztf_names[i])\n",
    "        object_dictionary['Label'].append(['SN II', 1])\n",
    "    else:\n",
    "        print('Warning : Not enought detections. Ignoring entry.')\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "save_file = open(\"pickle_lightcurves.pickle\", mode='wb')\n",
    "pickle.dump(object_dictionary, save_file)\n",
    "save_file.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Adding in non-detections & interpolating the light curves\n",
    "#processed_data = preprocessing('pickle_lightcurves.pickle',Version,timediff,noofpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.863    16.580412 18.9924   16.364395 16.240137 16.66374  16.995054\n",
      " 17.247751 18.422678 18.880629]\n",
      "[58743.2079745 58747.2773032 58750.2082639 59335.4405671 59338.4472106\n",
      " 59340.441169  59342.4675463 59345.4266088 59348.4435648 59354.4437384]\n",
      "[-1.          0.0389301   0.198369    0.03921192  0.03599869  0.04902661\n",
      "  0.04449942  0.04719749  0.07475115  0.15144286]\n"
     ]
    }
   ],
   "source": [
    "print(datadict['Data'][0]['R_mag_wn'])\n",
    "print(datadict['Data'][0]['R_mjd_wn'])\n",
    "print(datadict['Data'][0]['R_err_wn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('pickle_lightcurves.pickle', \"rb\")\n",
    "datadict = pickle.load(file)\n",
    "dummy_dict, source_idx = initialise(datadict,timediff,noofpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_R, error_R = interpolate(datadict['Data'][0]['R_mag_wn'], \n",
    "                                               datadict['Data'][0]['R_err_wn'], \n",
    "                                               datadict['Data'][0]['R_mjd_wn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(source_idx)):\n",
    "\n",
    "    index = source_idx[row]\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Interpolate the data\n",
    "        interpolated = source_interpolate(datadict['Data'][index])\n",
    "        dummy_dict = array_update(dummy_dict, interpolated, row)\n",
    "\n",
    "    except:\n",
    "\n",
    "        print('\\nERROR : Interpolation failed. Discarding entry.\\n')\n",
    "        dummy_dict['failed'].append([index, datadict['Name'][index], datadict['Label'][index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-d89876f6afdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelsfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailsfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data Dimensions :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    440\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[1;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[0;32m    728\u001b[0m                              \"allow_pickle=False\")\n\u001b[0;32m    729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "datafile = 'Data/'+Version+'/data_lc.npy'\n",
    "labelsfile = 'Data/'+Version+'/labels.npy'\n",
    "failsfile = 'Data/'+Version+'/fails.npy'\n",
    "\n",
    "data = np.load(datafile)\n",
    "labels = np.load(labelsfile)\n",
    "fails = np.load(failsfile)\n",
    "\n",
    "print('Data Dimensions :', data.shape)\n",
    "print('Label Dimensions :', labels.shape)\n",
    "print('Fails Dimensions :', fails.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-681e9744c24f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mplotbool\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"Yes\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'y'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'Y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mscs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'processed_data' is not defined"
     ]
    }
   ],
   "source": [
    "##### Plot lightcuves AND interpolated light curves\n",
    "\n",
    "if plotbool == 1 or \"Yes\" or 'y' or 'Y':\n",
    "    for scs in processed_data:\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        fig.suptitle(\"NAME\")\n",
    "        # Real data\n",
    "        ax[0,0].plt.scatter(datadict['Data'][index]['R_mjd'], datadict['Data'][index]['R_mag'], 60, color=[(232/256, 63/256, 72/256)], label='R-band')\n",
    "        ax[0,0].plt.scatter(datadict['Data'][index]['G_mjd'], datadict['Data'][index]['G_mag'], 60, color=[(31/256, 208/256, 130/256)], label='G-band')\n",
    "        ax[0,0].plt.xlabel('Time [MJD]', fontsize=20)\n",
    "        ax[0,0].plt.ylabel('Apparent Magnitude', fontsize=20)\n",
    "        ax[0,0].plt.gca().invert_yaxis()\n",
    "        ax[0,0].plt.grid()\n",
    "        ax[0,0].plt.legend()\n",
    "        ax[0,0].plt.title(datadict['Label'][index][0], fontsize=20)\n",
    "        # Interpolated data\n",
    "        ax[0,1].plt.scatter(datadict['Data'][index]['R_mjd'], datadict['Data'][index]['R_mag'], 60, color=[(232/256, 63/256, 72/256)], label='R-band')\n",
    "        ax[0,1].plt.scatter(datadict['Data'][index]['G_mjd'], datadict['Data'][index]['G_mag'], 60, color=[(31/256, 208/256, 130/256)], label='G-band')\n",
    "        ax[0,1].plt.xlabel('Normalized time', fontsize=20)\n",
    "        ax[0,1].plt.ylabel('Normalized Flux', fontsize=20)\n",
    "        ax[0,1].plt.gca().invert_yaxis()\n",
    "        ax[0,1].plt.grid()\n",
    "        ax[0,1].plt.legend()\n",
    "        ax[0,1].plt.title(datadict['Label'][index][0], fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Classify it\n",
    "\n",
    "\n",
    "\n",
    "X_train = torch()\n",
    "\n",
    "# Model Building\n",
    "input_dim = X_train.shape[2]\n",
    "num_classes = Y_train.shape[1]\n",
    "hidden_dim = 64\n",
    "n_layers = 1\n",
    "\n",
    "Net = simple_ENID(input_dim=input_dim, hidden_dim =hidden_dim, output_dim=num_classes, n_layers=n_layers)\n",
    "print(Net)\n",
    "\n",
    "Net.load_state_dict(torch.load(ModelWeights))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ZTF19abzwbxy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyENID(datasources,Version,ModelWeights,timediff,noofpoints,plotbool):\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
