{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b334162",
   "metadata": {},
   "source": [
    "## Considerations for Classification\n",
    "Here we have written down some fundamental considerations that have to be made for our given classification problem. \n",
    "\n",
    "#### Small, imbalanced dataset\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n",
    "- The dataset is quite small, which means that we cannot allow ourselves to split it up in multiple pieces for training, testing and validation. We will consider a 0.9/0.1 proportion of split of training and validation set. Within the 90% of training, we will use k-fold cross-validation to see how the model performs on unseen data before feeding it the validation set (the truly unseen data).\n",
    "- It is imbalanced. \n",
    "- Performance Metric : consider another peformance metric than accuracy (F1 score, for example) and confusion matrices to manually investigate the outputs and see if the model truly learned something, or if it is simply reflecting the underlying distribution of data (i.e. the class imbalance just makes it predict the most common class to achieve a good result, which we do not want). \n",
    "- Resampling data : We can oversample or undersample our data (add or remove samples from respectively the smaller and larger classes) to achieve a better balance. Because we have little data in our case, oversampling is probably the best option. It may lead to over-fitting, though. If we use over-sampling, it should be carried out as a step AFTER cross-validation partitioning, to avoid over-fitting as much as possible.\n",
    "- Penalised model : we can penalise the model more if it misclassifies the minority classes. It should however be inverstigated whether this is possible for a problem with many minority classes. This should be added in the cost function estimates, but we need to find out how to do this for a PyTorch neural network. \n",
    "\n",
    "#### Current Pipeline : \n",
    "1. Pull lightcurves for ZTF sources from Alerce, get classes from TNS\n",
    "2. Interpolate the data and merge all lightcurves in a single array\n",
    "3. One-hot encode labels\n",
    "4. Create training and test sets (proportions 90%/10%)\n",
    "5. Use K-fold cross validation for model training\n",
    "6. Over-sample the minority classes in each fold from the training set\n",
    "\n",
    "On K-fold cross-validation implementation in PyTorch : \n",
    "\n",
    "https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/#summary-and-code-example-k-fold-cross-validation-with-pytorch\n",
    "\n",
    "#### Input to RNN\n",
    "- The RNN has no information about the time, so we need to feed it an array containing the lightcurve magnitude data points for each source. Ideally, the \"timestep\" (that it does not know) should be the same between each point, so that the RNN sees a data point for a source every X minutes/hours/days in all cases. This is an important pre-processing step for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eeca16",
   "metadata": {},
   "source": [
    "## Import Packages and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4660724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data.Dataset as Dataset\n",
    "import torch.utils.data.DataLoader as DataLoader\n",
    "\n",
    "# Encode Labels\n",
    "# Create Dataset Class\n",
    "# Create DataLoader\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__():\n",
    "        \n",
    "    def get_item():\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523af09",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENID(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "\n",
    "Net = ENID()\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516755d",
   "metadata": {},
   "source": [
    "## Training\n",
    "#### Cost Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1fa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9cc3a62",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04524446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
